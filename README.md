# ERAV3_Assignment6

This repository contains code for training a neural network on the MNIST dataset.

## Setup

1. Clone this repository
```bash
git clone https://github.com/yourusername/ERAV3_Assignment6.git
cd ERAV3_Assignment6
```

2. Create and activate a virtual environment (optional but recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```

3. Install dependencies
```bash
pip install -r requirements.txt
```

## Network Architecture

The model uses a Convolutional Neural Network (CNN) with the following architecture:

### Input Layer
- Input Image Size: 28x28x1 (MNIST grayscale images)

### Feature Extraction Layers

#### Block 1
1. Convolution Layer 1
   - Input: 1 channel, Output: 12 channels
   - Kernel: 3x3, Padding: 1
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×1×12) + 12 = 120 conv params + 24 BN params = 144 params

2. Convolution Layer 2
   - Input: 12 channels, Output: 32 channels
   - Kernel: 3x3, Padding: 1
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×12×32) + 32 = 3,488 conv params + 64 BN params = 3,552 params

3. Transition Block 1
   - MaxPool(2x2)
   - 1x1 Convolution: 32 → 12 channels
   - Parameters: (1×1×32×12) + 12 = 396 params

#### Block 2
4. Convolution Layer 3
   - Input: 12 channels, Output: 16 channels
   - Kernel: 3x3, Padding: 1
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×12×16) + 16 = 1,744 conv params + 32 BN params = 1,776 params

5. Convolution Layer 4
   - Input: 16 channels, Output: 32 channels
   - Kernel: 3x3, Padding: 1
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×16×32) + 32 = 4,640 conv params + 64 BN params = 4,704 params

6. Transition Block 2
   - MaxPool(2x2)
   - 1x1 Convolution: 32 → 12 channels
   - Parameters: (1×1×32×12) + 12 = 396 params

#### Block 3
7. Convolution Layer 5
   - Input: 12 channels, Output: 32 channels
   - Kernel: 3x3, Padding: 1
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×12×32) + 32 = 3,488 conv params + 64 BN params = 3,552 params

8. Convolution Layer 6
   - Input: 32 channels, Output: 10 channels
   - Kernel: 3x3, Padding: 0
   - BatchNorm, Dropout(0.1), ReLU
   - Parameters: (3×3×32×10) + 10 = 2,890 conv params + 20 BN params = 2,910 params

### Output Block
- Global Average Pooling
- Log Softmax
- Parameters: 0 (no trainable parameters)

### Total Parameters: 17,430

### Parameter Distribution
- Block 1: 4,092 parameters (23.5%)
- Block 2: 6,876 parameters (39.4%)
- Block 3: 6,462 parameters (37.1%)
- Output Block: 0 parameters (0%)

### Key Features
- Uses Batch Normalization after each convolution layer
- Implements Dropout (0.1) for regularization
- Uses Global Average Pooling instead of Fully Connected layers
- Two transition blocks with MaxPooling for spatial dimension reduction
- ReLU activation throughout the network

## Training

To train the model, simply run:
```bash
python train.py
```

## Model Performance

The model achieves:
- Best Test Accuracy: 99.41% (Epoch 19)
- Consistent performance above 99% after epoch 5
- Training completed in 19 epochs

### Training Logs
```
(venv) sravan@sravan-latitude-3410 ~/Personal/Courses/ERA3/Assignment6/ERAV3_Assignment6 (main)$ python train.py 
-----------------------------------------------------
Epoch  1 :
-----------------------------------------------------
loss=0.34633564949035645 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:14<00:00,  6.31it/s]

Test set: Average loss: 0.3104, Accuracy: 9826/10000 (98.26%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  2 :
-----------------------------------------------------
loss=0.1478656381368637 batch_id=468: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:38<00:00,  4.76it/s]

Test set: Average loss: 0.2085, Accuracy: 9794/10000 (97.94%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  3 :
-----------------------------------------------------
loss=0.10153745859861374 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:36<00:00,  4.85it/s]

Test set: Average loss: 0.1081, Accuracy: 9886/10000 (98.86%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  4 :
-----------------------------------------------------
loss=0.0775560662150383 batch_id=468: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:43<00:00,  4.53it/s]

Test set: Average loss: 0.0829, Accuracy: 9878/10000 (98.78%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  5 :
-----------------------------------------------------
loss=0.08842161297798157 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:34<00:00,  4.95it/s]

Test set: Average loss: 0.0559, Accuracy: 9919/10000 (99.19%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  6 :
-----------------------------------------------------
loss=0.062242794781923294 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:49<00:00,  4.29it/s]

Test set: Average loss: 0.0471, Accuracy: 9916/10000 (99.16%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  7 :
-----------------------------------------------------
loss=0.058587659150362015 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:47<00:00,  4.36it/s]

Test set: Average loss: 0.0347, Accuracy: 9930/10000 (99.30%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  8 :
-----------------------------------------------------
loss=0.04753868281841278 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:50<00:00,  4.23it/s]

Test set: Average loss: 0.0359, Accuracy: 9914/10000 (99.14%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  9 :
-----------------------------------------------------
loss=0.06070408597588539 batch_id=468: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████��██████| 469/469 [02:00<00:00,  3.89it/s]

Test set: Average loss: 0.0319, Accuracy: 9925/10000 (99.25%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  10 :
-----------------------------------------------------
loss=0.024811269715428352 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:43<00:00,  4.52it/s]

Test set: Average loss: 0.0437, Accuracy: 9896/10000 (98.96%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  11 :
-----------------------------------------------------
loss=0.055425602942705154 batch_id=468: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████��████████████| 469/469 [01:30<00:00,  5.18it/s]

Test set: Average loss: 0.0314, Accuracy: 9916/10000 (99.16%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  12 :
-----------------------------------------------------
loss=0.040127869695425034 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:15<00:00,  6.24it/s]

Test set: Average loss: 0.0347, Accuracy: 9890/10000 (98.90%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  13 :
-----------------------------------------------------
loss=0.05778532102704048 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:13<00:00,  6.40it/s]

Test set: Average loss: 0.0324, Accuracy: 9903/10000 (99.03%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  14 :
-----------------------------------------------------
loss=0.03817911446094513 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:14<00:00,  6.31it/s]

Test set: Average loss: 0.0249, Accuracy: 9930/10000 (99.30%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  15 :
-----------------------------------------------------
loss=0.011074066162109375 batch_id=468: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████���█████████████████████████| 469/469 [01:10<00:00,  6.62it/s]

Test set: Average loss: 0.0358, Accuracy: 9893/10000 (98.93%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  16 :
-----------------------------------------------------
loss=0.01850918121635914 batch_id=468: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:10<00:00,  6.67it/s]

Test set: Average loss: 0.0256, Accuracy: 9923/10000 (99.23%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  17 :
-----------------------------------------------------
loss=0.010851263999938965 batch_id=468: 100%|███████████████████████████████████████████████████████████████████████████████████████████��████████████████████████████████| 469/469 [01:13<00:00,  6.41it/s]

Test set: Average loss: 0.0229, Accuracy: 9932/10000 (99.32%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  18 :
-----------------------------------------------------
loss=0.038540881127119064 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:16<00:00,  6.12it/s]

Test set: Average loss: 0.0256, Accuracy: 9920/10000 (99.20%)

-----------------------------------------------------
-----------------------------------------------------
Epoch  19 :
-----------------------------------------------------
loss=0.013515288941562176 batch_id=468: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [01:20<00:00,  5.84it/s]

Test set: Average loss: 0.0219, Accuracy: 9941/10000 (99.41%)

-----------------------------------------------------
```

The model shows steady improvement across epochs:
- Epoch 1: 98.26% accuracy
- Epoch 5: 99.19% accuracy
- Epoch 10: 98.96% accuracy
- Epoch 15: 98.93% accuracy
- Final Epoch (19): 99.41% accuracy

## Training Parameters
- Batch Size: The model is trained in batches
- Optimizer: Used for model parameter updates
- Learning Rate Schedule: Appears to use a learning rate scheduler based on the presence of train2_steplr.py

Note: For complete network architecture details and specific hyperparameters, please refer to the model/network.py file.
```